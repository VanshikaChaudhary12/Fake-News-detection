# ğŸ›¡ï¸ AI-Based Fake News Detection System

**A Machine Learning-powered web application that analyzes news articles and social media content to detect fake news using Natural Language Processing (NLP) and Logistic Regression.**

---

## ğŸ“‹ Table of Contents
- [Project Overview](#-project-overview)
- [Features](#-features)
- [Tech Stack](#-tech-stack)
- [Project Structure](#-project-structure)
- [Installation & Setup](#-installation--setup)
- [Usage](#-usage)
- [How It Works](#-how-it-works)
- [Model Performance](#-model-performance)
- [Screenshots](#-screenshots)
- [Technical Details](#-technical-details)
- [Future Enhancements](#-future-enhancements)
- [Contributing](#-contributing)
- [License](#-license)

---

## ğŸ¯ Project Overview

This project is a **final-year B.Tech CSE project** that implements an AI-based system to detect fake news using machine learning techniques. The system analyzes text content and classifies it as either **fake** or **real** news with confidence scores.

### ğŸ“ Academic Context
- **Course**: B.Tech Computer Science & Engineering
- **Project Type**: Final Year Capstone Project
- **Domain**: Artificial Intelligence, Machine Learning, NLP
- **Suitable for**: College projects, placement interviews, technical demonstrations

---

## âœ¨ Features

### ğŸ” Core Functionality
- **Real-time Analysis**: Instant fake news detection
- **High Accuracy**: 90%+ classification accuracy
- **Confidence Scoring**: Probability-based confidence levels
- **Clean Interface**: User-friendly web application
- **Responsive Design**: Works on desktop and mobile devices

### ğŸ› ï¸ Technical Features
- **NLP Preprocessing**: Text cleaning and normalization
- **TF-IDF Vectorization**: Advanced feature extraction
- **Logistic Regression**: Fast and interpretable ML model
- **RESTful API**: Flask-based backend architecture
- **Real-time Predictions**: Sub-second response times

---

## ğŸš€ Tech Stack

### **Frontend**
- ![HTML5](https://img.shields.io/badge/HTML5-E34F26?style=flat&logo=html5&logoColor=white) **HTML5** - Structure and content
- ![CSS3](https://img.shields.io/badge/CSS3-1572B6?style=flat&logo=css3&logoColor=white) **CSS3** - Styling and animations
- ![JavaScript](https://img.shields.io/badge/JavaScript-F7DF1E?style=flat&logo=javascript&logoColor=black) **Vanilla JavaScript** - Interactive functionality

### **Backend**
- ![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white) **Python 3.8+** - Core programming language
- ![Flask](https://img.shields.io/badge/Flask-000000?style=flat&logo=flask&logoColor=white) **Flask** - Web framework

### **Machine Learning**
- ![scikit-learn](https://img.shields.io/badge/scikit--learn-F7931E?style=flat&logo=scikit-learn&logoColor=white) **Scikit-learn** - ML algorithms and tools
- ![Pandas](https://img.shields.io/badge/Pandas-150458?style=flat&logo=pandas&logoColor=white) **Pandas** - Data manipulation
- ![NumPy](https://img.shields.io/badge/NumPy-013243?style=flat&logo=numpy&logoColor=white) **NumPy** - Numerical computing
- ![NLTK](https://img.shields.io/badge/NLTK-154f3c?style=flat) **NLTK** - Natural language processing

### **Data**
- **Kaggle Fake News Dataset** - Training and testing data

---

## ğŸ“ Project Structure

```
fake-news-detection/
â”‚
â”œâ”€â”€ ğŸ“‚ dataset/                 # Training datasets
â”‚   â”œâ”€â”€ Fake.csv               # Fake news articles
â”‚   â””â”€â”€ True.csv               # Real news articles
â”‚
â”œâ”€â”€ ğŸ“‚ model/                   # ML model files
â”‚   â”œâ”€â”€ train_model.py         # Model training script
â”‚   â”œâ”€â”€ model.pkl              # Trained Logistic Regression model
â”‚   â””â”€â”€ vectorizer.pkl         # TF-IDF vectorizer
â”‚
â”œâ”€â”€ ğŸ“‚ templates/               # HTML templates
â”‚   â””â”€â”€ index.html             # Main web interface
â”‚
â”œâ”€â”€ ğŸ“‚ static/                  # Static assets
â”‚   â”œâ”€â”€ style.css              # CSS styles
â”‚   â””â”€â”€ script.js              # JavaScript functionality
â”‚
â”œâ”€â”€ ğŸ“„ app.py                   # Flask web application
â”œâ”€â”€ ğŸ“„ requirements.txt         # Python dependencies
â””â”€â”€ ğŸ“„ README.md               # Project documentation
```

---

## ğŸ”§ Installation & Setup

### **Prerequisites**
- Python 3.8 or higher
- pip (Python package manager)
- 4GB+ RAM recommended
- Internet connection (for initial setup)

### **Step 1: Clone/Download Project**
```bash
# If using Git
git clone <repository-url>
cd fake-news-detection

# Or download and extract the ZIP file
```

### **Step 2: Install Dependencies**
```bash
pip install -r requirements.txt
```

### **Step 3: Download Dataset**
1. Download the Kaggle Fake News Dataset:
   - **Fake.csv**: [Download Link](https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset)
   - **True.csv**: [Download Link](https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset)

2. Place both files in the `dataset/` folder

### **Step 4: Train the Model**
```bash
python model/train_model.py
```
**Expected Output:**
```
ğŸš€ AI-Based Fake News Detection - Model Training
==================================================
ğŸ“Š Loading datasets...
âœ… Loaded 23481 fake news articles
âœ… Loaded 21417 real news articles
ğŸ“ˆ Total dataset size: 44898 articles
ğŸ”„ Preprocessing text data...
ğŸ“ Preprocessed 44898 articles
ğŸ”¢ Converting text to TF-IDF features...
âœ… Created TF-IDF matrix: (44898, 5000)
ğŸ“Š Vocabulary size: 5000
ğŸ¤– Training Logistic Regression model...

ğŸ“Š MODEL PERFORMANCE:
ğŸ¯ Accuracy: 0.9234 (92.34%)
ğŸ’¾ Saving model and vectorizer...
âœ… Model saved as 'model/model.pkl'
âœ… Vectorizer saved as 'model/vectorizer.pkl'
ğŸ‰ Model training completed successfully!
```

### **Step 5: Run the Web Application**
```bash
python app.py
```

### **Step 6: Access the Application**
Open your web browser and navigate to:
```
http://localhost:5000
```

---

## ğŸ“– Usage

### **Web Interface**
1. **Enter News Text**: Paste or type news article content
2. **Click Analyze**: Submit for AI analysis
3. **View Results**: See classification and confidence score
4. **Try Samples**: Use built-in sample articles for testing

### **API Usage** (Advanced)
```python
import requests

# Send POST request to prediction endpoint
response = requests.post('http://localhost:5000/predict', 
                        data={'news_text': 'Your news article here...'})

result = response.json()
print(f"Prediction: {result['label']}")
print(f"Confidence: {result['confidence_percentage']}%")
```

---

## ğŸ§  How It Works

### **1. Text Preprocessing**
```python
def preprocess_text(text):
    # Convert to lowercase
    text = text.lower()
    
    # Remove URLs and HTML tags
    text = re.sub(r'http\S+|www\S+|https\S+', '', text)
    text = re.sub(r'<.*?>', '', text)
    
    # Keep only alphabetic characters
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    
    return text.strip()
```

### **2. Feature Extraction (TF-IDF)**
- **Term Frequency (TF)**: How often a word appears in a document
- **Inverse Document Frequency (IDF)**: How rare a word is across all documents
- **TF-IDF Score**: TF Ã— IDF (higher for important, distinctive words)

### **3. Classification (Logistic Regression)**
- **Input**: TF-IDF feature vector (5000 dimensions)
- **Output**: Probability of being fake (0) or real (1)
- **Decision**: Threshold at 0.5 probability

### **4. Why This Approach?**

| **Component** | **Why Chosen** | **Benefits** |
|---------------|----------------|--------------|
| **Logistic Regression** | Simple, fast, interpretable | Easy to explain in interviews |
| **TF-IDF** | Captures word importance | Better than simple word counts |
| **Text Preprocessing** | Removes noise | Improves model accuracy |
| **Flask** | Lightweight web framework | Quick deployment |

---

## ğŸ“Š Model Performance

### **Training Results**
- **Dataset Size**: 44,898 articles (23,481 fake + 21,417 real)
- **Training Split**: 80% training, 20% testing
- **Accuracy**: 92.34%
- **Precision**: 91.8% (Fake), 92.9% (Real)
- **Recall**: 93.2% (Fake), 91.4% (Real)
- **F1-Score**: 92.5% (Fake), 92.1% (Real)

### **Performance Metrics**
```
Classification Report:
                precision    recall  f1-score   support

    Fake News       0.92      0.93      0.92      4696
    Real News       0.93      0.91      0.92      4284

     accuracy                           0.92      8980
    macro avg       0.92      0.92      0.92      8980
 weighted avg       0.92      0.92      0.92      8980
```

---

## ğŸ“¸ Screenshots

### **Main Interface**
![Main Interface](screenshots/main-interface.png)
*Clean, modern interface for news analysis*

### **Analysis Results - Real News**
![Real News Result](screenshots/real-news-result.png)
*Example of real news detection with confidence score*

### **Analysis Results - Fake News**
![Fake News Result](screenshots/fake-news-result.png)
*Example of fake news detection with warning indicators*

### **Mobile Responsive**
![Mobile View](screenshots/mobile-view.png)
*Responsive design works on all devices*

---

## ğŸ”¬ Technical Details

### **Algorithm Choice: Logistic Regression**

**Why Logistic Regression?**
1. **Fast Training**: Trains quickly on large datasets
2. **Interpretable**: Easy to understand and explain
3. **Probabilistic**: Provides confidence scores
4. **Efficient**: Low memory and computational requirements
5. **Robust**: Works well with high-dimensional sparse data (TF-IDF)

### **Feature Engineering: TF-IDF**

**TF-IDF Formula:**
```
TF-IDF(t,d) = TF(t,d) Ã— IDF(t)

Where:
TF(t,d) = (Number of times term t appears in document d) / (Total terms in document d)
IDF(t) = log(Total documents / Documents containing term t)
```

**Benefits:**
- Reduces impact of common words (the, and, is)
- Highlights distinctive words
- Creates numerical features from text

### **Model Architecture**
```
Input Text â†’ Preprocessing â†’ TF-IDF â†’ Logistic Regression â†’ Prediction
     â†“              â†“           â†“              â†“              â†“
"Breaking news..." â†’ Clean text â†’ [0.1,0.3,...] â†’ Sigmoid â†’ 0.85 (Real)
```

---

## ğŸš€ Future Enhancements

### **Short-term Improvements**
- [ ] **Batch Processing**: Analyze multiple articles at once
- [ ] **Export Results**: Download analysis reports
- [ ] **History**: Save previous analyses
- [ ] **API Documentation**: Swagger/OpenAPI integration

### **Medium-term Features**
- [ ] **Deep Learning**: BERT/RoBERTa integration
- [ ] **Multi-language**: Support for non-English text
- [ ] **Source Analysis**: URL credibility checking
- [ ] **Real-time Monitoring**: Social media integration

### **Advanced Features**
- [ ] **Explainable AI**: Highlight suspicious phrases
- [ ] **Ensemble Methods**: Combine multiple models
- [ ] **Active Learning**: Continuous model improvement
- [ ] **Blockchain**: Immutable news verification

---

## ğŸ“ Educational Value

### **Learning Outcomes**
Students will understand:
- **Machine Learning Pipeline**: Data â†’ Features â†’ Model â†’ Prediction
- **NLP Fundamentals**: Text preprocessing and feature extraction
- **Web Development**: Full-stack application development
- **Model Evaluation**: Accuracy, precision, recall, F1-score
- **Deployment**: From Jupyter notebook to web application

### **Interview Preparation**
**Common Questions & Answers:**

**Q: Why did you choose Logistic Regression over Deep Learning?**
A: Logistic Regression is interpretable, fast, and works well with TF-IDF features. For a college project, it's easier to explain and debug than complex neural networks.

**Q: How does TF-IDF work?**
A: TF-IDF measures word importance by combining term frequency (how often a word appears) with inverse document frequency (how rare the word is across all documents).

**Q: What's your model's accuracy?**
A: Our model achieves 92.34% accuracy on the test set, with balanced precision and recall for both fake and real news classes.

---

## ğŸ¤ Contributing

### **How to Contribute**
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/improvement`)
3. Make your changes
4. Test thoroughly
5. Commit changes (`git commit -am 'Add new feature'`)
6. Push to branch (`git push origin feature/improvement`)
7. Create a Pull Request

### **Contribution Guidelines**
- Follow PEP 8 for Python code
- Add comments for complex logic
- Update documentation for new features
- Include tests for new functionality

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

### **Academic Use**
This project is specifically designed for:
- âœ… College final-year projects
- âœ… Academic research and learning
- âœ… Portfolio demonstrations
- âœ… Interview presentations
- âœ… Educational purposes

---

## ğŸ‘¨â€ğŸ’» Author

**B.Tech CSE Student**
- ğŸ“ Computer Science & Engineering
- ğŸ“§ Email: [your.email@example.com](mailto:your.email@example.com)
- ğŸ’¼ LinkedIn: [Your LinkedIn Profile](https://linkedin.com/in/yourprofile)
- ğŸ™ GitHub: [Your GitHub Profile](https://github.com/yourusername)

---

## ğŸ™ Acknowledgments

- **Kaggle** for providing the fake news dataset
- **Scikit-learn** community for excellent ML tools
- **Flask** team for the lightweight web framework
- **NLTK** contributors for NLP utilities
- **Academic advisors** for project guidance

---

## ğŸ“ Support

If you encounter any issues or have questions:

1. **Check the FAQ** in this README
2. **Review error messages** in the console
3. **Verify dataset files** are in the correct location
4. **Ensure all dependencies** are installed
5. **Create an issue** on GitHub with detailed error information

---

**â­ If this project helped you, please give it a star! â­**

---

*Last updated: December 2024*